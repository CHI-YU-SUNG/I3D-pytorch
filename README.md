# I3D-pytorch
## 99% come from https://github.com/dxli94/WLASL
## Welcome to WLASL Homepage
WLASL is the <b>largest video dataset for Word-Level American Sign Language (ASL) recognition</b>, which features 2,000 common different words in ASL. We hope WLASL will facilitate the research in sign language understanding and eventually benefit the communication between deaf and hearing communities.

<iframe width="823" height="310" src="https://www.youtube.com/embed/wG-uaee4mJ4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Download
---------------
Please clone our [repository](https://github.com/dxli94/WLASL) for downloading. We suggest reading [README](https://github.com/dxli94/WLASL/blob/master/README.md) before using the dataset.

We strive to ensure our users have an easy access to WLASL. If you encounter any issue in downloading, e.g. invalid links, please contact dongxu.li@anu.edu.au for assistance.

News
---------------
* <span style="color: red"><b>NEW:</b></span> Pre-trained I3D and Pose-TGCN models and training code all released!
* Mar.29,2020  Now you can download all the WLASL videos by pressing a single button. Please check out our repo.
* Mar.16,2020 <span style="font-weight:bold">release of WLASL_v0.3</span>.
* Mar. 11, 2020: release of WLASL_v0.2. Updated expired links.
* Mar. 5, 2020: Our work on <b>WLASL</b> dataset received WACV 2020 <span style="color: red"><b>Best Paper Honourable Mention (Applications)</b></span>, out of nearly 1,000 submissions!
* Jan. 20, 2020: release of WLASL_v0.1! Pretrained models will follow shortly (or upon request for urgent use).


License
---------------
Licensed under the Computational Use of Data Agreement (C-UDA). Plaese refer to `C-UDA-1.0.pdf` for more information.

Disclaimer
---------------
All the WLASL data is intended for academic and computational use only. No commercial usage is allowed. We highly respect copyright and privacy. If you find WLASL violates your rights, please contact us.


Citation
--------------

Please cite the [WLASL paper](https://arxiv.org/abs/1910.11006) if it helps your research:
```bibtex
    @inproceedings{li2020word,
      title={Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison},
      author={Li, Dongxu and Rodriguez, Cristian and Yu, Xin and Li, Hongdong},
      booktitle={The IEEE Winter Conference on Applications of Computer Vision},
      pages={1459--1469},
      year={2020}
    }
```
and our CVPR 2020 [Best Paper Finalist paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Transferring_Cross-Domain_Knowledge_for_Video_Sign_Language_Recognition_CVPR_2020_paper.pdf)
```bibtex
@inproceedings{li2020transferring,
  title={Transferring cross-domain knowledge for video sign language recognition},
  author={Li, Dongxu and Yu, Xin and Xu, Chenchen and Petersson, Lars and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6205--6214},
  year={2020}
}
```
Other works using WLASL dataset you might also be interested:
```bibtex
@inproceedings{li2020tspnet,
	title        = {TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation},
	author       = {Li, Dongxu and Xu, Chenchen and Yu, Xin and Zhang, Kaihao and Swift, Benjamin and Suominen, Hanna and Li, Hongdong},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 33
}
```


